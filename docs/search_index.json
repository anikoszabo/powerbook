[["index.html", "Power and Sample Size Manual Welcome", " Power and Sample Size Manual Aniko Szabo 2023-03-29 Welcome This repository is for a Bookdown version of a reference book for power and sample size calculations using R. It is very much a work in progress, and fixes/contributions in the form of pull requests are welcome. "],["one-sample-mean-precision-based-sample-size.html", "1 One-sample mean: precision-based sample size 1.1 Example 1.2 Data generating mechanism 1.3 Precision measures 1.4 Simulation study 1.5 Getting inputs 1.6 Example revisited 1.7 Functions in R packages", " 1 One-sample mean: precision-based sample size Co-author: Alyssa Bivens 1.1 Example The Patient-Reported Outcomes Measurement Information System (PROMIS) provides validated questionnaires for a wide range of quality-of-life outcomes in the domains of physical, mental, and social health. The responses from a subject are summarized with a T-score, which has a mean 50 and standard deviation of 10 in the US general population. An investigator wants to study anxiety in the population of patients with cyclic vomiting syndrome (CVS) using the PROMIS Anxiety scale to see if they report more anxiety (ie higher T-scores on the scale) than the general population. How many subjects are needed? 1.2 Data generating mechanism Independently identically distributed observations \\(X_1, \\ldots, X_n\\) with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), with \\(\\mu\\) being the parameter of interest. The population mean \\(\\mu\\) is estimated by the sample mean \\(\\bar{X}_n\\) = \\(\\frac{\\sum(X_i)}{n}\\). 1.3 Precision measures 1.3.1 Standard error To calculate standard error (SE) or sample size (n) from standard error, it is \\(\\underline{not}\\) required for the underlying distribution to be normal. The standard error of sample mean is \\(SE(\\bar{X}) = \\frac{\\sigma}{\\sqrt{n}}\\). Solving for \\(n\\), we have \\[n= \\frac{\\sigma^{2}}{SE^2},\\] where SE is the targeted standard error of the estimate. #&#39;Calculate standard error for given sample size, or vice versa. Exactly one of &#39;n&#39; and &#39;se&#39; has to be NULL #&#39;sd - expected standard deviation #&#39;n - sample size #&#39;se - standard error of estimated mean se_mean &lt;- function (sd, n=NULL, se=NULL) { if(is.null(n) &amp; !is.null(se)) { (n&lt;-(sd^2)/se^2) } else if (!is.null(n) &amp; is.null(se)){ (se &lt;- sd/sqrt(n)) } else stop(&quot;Exactly one of &#39;n&#39; and &#39;se&#39; has to be NULL; &#39;sd&#39; must be known&quot;) res &lt;- list (n = n, sd = sd, se = se) res } 1.3.2 Confidence Interval Another way to quantify the precision of the estimated mean is the width of the resulting two-sided confidence interval, usually at a 95% confidence level. The half of the width of a symmetric 95% confidence interval is also called the margin of error. There are two methods for estimating a confidence interval for a mean, which result in symmetric intervals. We can use the \\(z\\)-based interval if the population standard deviation (\\(\\sigma\\)) is known, and the \\(t\\)-based confidence interval if \\(\\sigma\\) is unknown. The confidence intervals are computed under the assumption that the data are normally distributed. However, according to the central limit theorem, with a sufficiently large sample size \\(n\\), the sample mean \\(\\bar{X}_n\\) will be normally distributed regardless of the population distribution. The \\(100(1-\\alpha)\\)% confidence interval for \\(\\mu\\) when \\(\\sigma\\) is known is \\(CI = \\bar{X} \\pm z_{\\frac {\\alpha}{2}}\\frac{\\sigma}{ \\sqrt n}\\). The confidence interval when \\(\\sigma\\) is unknown is \\(CI = \\bar{X} \\pm t_{\\frac{\\alpha}{2}, n-1}\\frac{s}{\\sqrt n},\\) where \\(t_{\\frac {\\alpha}{2}, n-1}\\) is the upper \\(\\frac{\\alpha}{2}\\)th quantile of the \\(t\\)-distribution with \\(n-1\\) degrees of freedom, and \\(s\\) is the sample standard deviation. To understand the difference between the \\(z\\)-based interval and \\(t\\)-based interval, consider the following graph: sample_sizes &lt;- c(3, 4, 5, 10, 30, 50, 100, 200) df &lt;- c(sample_sizes - 1) t_values &lt;- qt(p=.05/2, df = df, lower.tail = FALSE) z &lt;- qnorm(p=.05/2, lower.tail=FALSE) xy &lt;- data.frame(n = sample_sizes, t = t_values, z = z) plot (xy$n, xy$t, type=&#39;o&#39;, col = &#39;red&#39;, xlab = &quot;Sample Size&quot;, ylab = &quot;Critical-Values&quot;, main = &quot;Critical-Values by Sample Size at 95% Confidence Level&quot;) points(xy$n, xy$z, col=&#39;blue&#39;, type=&quot;o&quot;, pch=4) legend(&quot;topright&quot;, legend = c(&quot;t-values&quot;, &quot;z-values&quot;), col=c(&quot;red&quot;, &quot;blue&quot;), pch=c(1,4), lty=1) The red line represents the \\(t\\) critical values associated with various sample sizes; the blue line represents the constant value of 1.959964, which is the \\(z\\) critical value. We can see that as the the sample size increases, the \\(t\\) critical value approaches the \\(z\\) critical value. The difference becomes small by a sample size of 30, which is the typically quoted cutoff for using the asymptotic test. The difference is barely noticeable after a sample size of 100. Overall, this shows that, in many instances, the difference between using a \\(t\\) critical-value and using a \\(z\\) critical-value is negligible. The prec_mean function in {presize} provides the sample size calculation for the \\(t\\)-based confidence interval. library(presize) str(prec_mean) ## function (mean, sd, n = NULL, conf.width = NULL, conf.level = 0.95, ..., ## mu = NULL) Note that the formulas above imply that the mean is a superfluous parameter, and can be set to any value. For completeness, the following function implements a \\(z\\)-based computation. # Function that can find the n or conf.width based on what is null. prec_mean_z &lt;- function (sd, n = NULL, conf.width = NULL, conf.level=.95) { alpha &lt;- (1-conf.level)/2 z &lt;- qnorm(alpha, lower.tail = FALSE) if(is.null(conf.width) &amp; !is.null(n)) { ci&lt;- (z*(sd/sqrt(n))) conf.width &lt;- 2 * ci res &lt;- list (sd = sd, n = n, conf.width = conf.width, conf.level = conf.level) res } else if(!is.null(conf.width) &amp; is.null(n)) { ci &lt;- conf.width/2 n &lt;- ((sd*z)/ci)^2 } else stop (&quot;Exactly one of &#39;n&#39; and &#39;conf.width&#39; must be NULL&quot;) res &lt;- list (sd = sd, n = n, conf.width = conf.width, conf.level = conf.level) res } 1.4 Simulation study # Write function to get n solve_n &lt;- function (precision, sd, conf.level=.95, n = NULL, method = c(&quot;SE&quot;, &quot;t-value&quot;, &quot;z-value&quot;)) { method &lt;- match.arg(method, choices = c(&quot;SE&quot;, &quot;t-value&quot;, &quot;z-value&quot;)) if (method == &quot;SE&quot;) { n &lt;- se_mean(sd = sd, n = NULL, se = precision)$n } else if(method == &quot;z-value&quot;) { n &lt;- prec_mean_z(sd = sd, n = NULL, conf.width = precision, conf.level = conf.level)$n } else if(method == &quot;t-value&quot;) { n &lt;- prec_mean (mean = 0, conf.width = precision, conf.level = conf.level, sd = sd)$n } else stop (&quot;&#39;method&#39; must be &#39;z&#39;, &#39;t&#39;, or &#39;SE&#39;&quot;) n &lt;- ceiling(n) return(n) } #Find n based on various sd, method, or, p. ## set vector of precision values (p0) and methods (m0) to explore p0 &lt;- seq(1, 5, by=.5) sd0 &lt;- 10 m0 &lt;- c(&quot;SE&quot;, &quot;t-value&quot;, &quot;z-value&quot;) # Data set with varying &#39;mean&#39; and &#39;w&#39; se_settings &lt;- expand.grid(p = p0, sd = sd0, m = m0, stringsAsFactors = FALSE) # Apply the sim mean functions to all possibilities like se_settings se_settings$n &lt;- sapply(1:nrow(se_settings), function(idx) with (se_settings, solve_n (precision = p[idx], sd = sd[idx], method = m[idx]))) library(ggplot2) ggplot(se_settings, aes(x = p, y = n, color = m, group = m)) + geom_line()+ scale_color_discrete(&quot;Method&quot;) + xlab(&quot;Target precision &#39;p&#39;&quot;) + ylab(&quot;Sample size &#39;n&#39;&quot;) + ggtitle(&quot;Sample size required to achieve target precision&quot;) Graph various simulated precision’s for various methods, distributions, and target precisions. # set up possible values for target precision, standard deviation, method, and distribution. p0 &lt;- seq(1, 5, by=.5) sd0 &lt;- 10 m0 &lt;- c(&quot;SE&quot;, &quot;t-value&quot;, &quot;z-value&quot;) d0 &lt;- c(&quot;normal&quot;, &quot;uniform&quot;, &quot;exp&quot;) sim_settings &lt;- rbind( expand.grid( sd = sd0, p = p0, method = m0, stringsAsFactors = FALSE, distribution = d0), expand.grid( sd = sd0, p = p0, method = m0, stringsAsFactors = FALSE, distribution = d0 )) # Allow function to be used from presize library(presize) # Create a function to calculate the simulated precisions. sim_mean &lt;- function (sd, n=NULL, conf.level = .95, precision, R = 1000, method = c(&quot;SE&quot;, &quot;t-value&quot;, &quot;z-value&quot;), distribution = c(&quot;normal&quot;, &quot;uniform&quot;, &quot;exp&quot;)) { # Allow variants of SE, t-value, and z-value; prevent non-characters from being allowed. method &lt;- match.arg(method, choices = c(&quot;SE&quot;, &quot;t-value&quot;, &quot;z-value&quot;)) # Find sample size (n) depending on method. if (method == &quot;SE&quot;) { n&lt;-(sd^2)/precision^2 } else if(method == &quot;z-value&quot;) { alpha &lt;- (1-conf.level)/2 z &lt;- qnorm(alpha, lower.tail = FALSE) ci &lt;- precision/2 n &lt;- ((sd*z)/ci)^2 } else if(method == &quot;t-value&quot;) { n &lt;- prec_mean (mean = 0, conf.width = precision, conf.level = conf.level, sd = sd)$n } else stop (&quot;&#39;method&#39; must be &#39;z&#39;, &#39;t&#39;, or &#39;SE&#39;&quot;) # Round n up to nearest interger. n &lt;- ceiling(n) #Simulate possible outcome with the predicted SD and the predicted n and various distributions. if (distribution == &quot;normal&quot;) se_vec &lt;- replicate (R, {x &lt;- rnorm(n = n, mean = 0, sd = sd); sd_x = sd(x); sd_x/sqrt(n)}) if (distribution == &quot;uniform&quot;) se_vec &lt;- replicate (R, {x &lt;- runif(n = n, min = 0, max = sd*sqrt(12)); sd_x = sd(x); sd_x/sqrt(n)}) ## To use the runif function the min and max must be calculated in relationship to standard deviation*. if (distribution == &quot;exp&quot;) se_vec &lt;- replicate (R, {x &lt;- rexp(n = n, rate = 1/sd); sd_x = sd(x); sd_x/sqrt(n)}) ##To use the rexp function the rate must be calculated in relationship to standard deviation**. if (method == &quot;t-value&quot;) { t_value &lt;- qt(p= (1 - conf.level)/2, df = n - 1, lower.tail = FALSE) t_ci &lt;- 2*(t_value*se_vec) } if (method == &quot;z-value&quot;) { z_value &lt;- qnorm (p = (1 - conf.level)/2, lower.tail = FALSE) z_ci &lt;- 2*(z_value*se_vec) } if (method == &quot;SE&quot;) { precision_dataframe &lt;- data.frame(sd = sd, n = n, method = &quot;SE&quot;, distribution = distribution, precision = se_vec, target = precision) } if (method == &quot;t-value&quot;) { precision_dataframe &lt;- data.frame(sd = sd, n = n, method = &quot;t-value&quot;, distribution = distribution, precision = t_ci, target = precision) } if (method == &quot;z-value&quot;) { precision_dataframe &lt;- data.frame(sd = sd, n = n, method = &quot;z-value&quot;, distribution = distribution, precision = z_ci, target = precision) } return(precision_dataframe) } #Run simulation for each value of the grid: set.seed(12345) sim_list &lt;- lapply (1:nrow(sim_settings), function(idx) with (sim_settings, sim_mean(precision = p[idx], sd = sd0, method = method[idx], distribution = distribution[idx], R = 1000))) sim_res &lt;- do.call(rbind, sim_list) # Graph sim_res library(ggplot2) ggplot(sim_res, aes (x=target, y = precision, color = factor(method))) + facet_grid(method~distribution, scales = &quot;free_y&quot;) + geom_boxplot(aes(group=interaction(method, distribution, target)), outlier.size = 1, outlier.alpha = 0.025) + scale_color_discrete(&quot;Targeted precision&quot;) + geom_abline(intercept = 0, slope = 1) Notes In the uniform distribution \\(\\frac{1}{\\sqrt{12}}(b-a) = sd\\) where b is the maximum, a is the minimum, and sd is the standard deviation. Because we only need to know the range, we can assign a value to a and solve it in relationship to b. Therefore, we can assign a (the minimum) as 0 and solve for b (the maximum). After solving for the maximum (b), we calculate that \\(b = sd*\\sqrt{12}\\). In the exponent distribution \\(sd = \\frac{1}{\\lambda}\\), where \\(\\lambda = rate\\). Therefore solving for rate, we calculate that \\(\\lambda = \\frac{1}{sd}\\). 1.5 Getting inputs 1.5.1 Estimating Standard Deviation To estimate n from sample error (or vice versa), standard deviation must be either known or estimated. Some ways to obtain an already known standard deviation, include researching standard deviations obtained from similar studies or using a universal, known standard deviation (depending on the type of study). If standard deviation cannot be obtained in this way, it must be estimated. Use information known about the value being collected to estimate an approximate minimum value collected and an approximate maximum value. For example, height of adults can have an estimated minimum collected value of 4 ft and 9 inches and estimated maximum collected value of 6 feet and 2 inches. While there are adults with heights below 4 feet and 9 inches and above 6 feet and 3 inches, they are very uncommon and therefore (by probability) not likely to be in the sample. Ideally, this will give a range close to the range of the data collected. After a range is estimated, we can then us a formula called the range rule for standard deviation which states the following: sd \\(\\approx \\frac{max-min}{4}\\) where sd = standard deviation, max = estimated maximum value, and min = estimated minimum value. #&#39; Calculate sample standard deviation for a given range. There must be exactly one one &#39;max&#39; and one &#39;min.&#39; #&#39; sd = standard deviation #&#39; max = estimated maximum value #&#39; min = estimated minimum value sd_from_range &lt;- function (max=max, min=min, sd=NULL) { sd &lt;- (max - min)/4 return(sd) } 1.6 Example revisited As stated in the example, we want to calculate the sample size (n) based on a t-score method and a claimed standard deviation of 10. Additionally, we know the mean is 50, but this is an unnecessary fact for calculating n. Since we are only finding the sample size, we would use the solve_n function created earlier. In order to find n, we need standard deviation, precision, and a chosen confidence level. The example gives us a known standard deviation of 10. To estimate precision, we can use other studies with similar studies and use what was obtained in them or use studies that determine minimally important differences (MIDs). For example, in this study we can use a study from the National Library of Medicine titled “estimating minimally important differences for the PROMIS pain interference scales: results from 3 randomized clinic trials” to determine an approximate minimally important differences (Source 1). Using the data, we can estimate a minimum importance difference (MID) of around 3 (Source 1), which means that in order to get the confidence width (or precision), which calculates the likelihood of it being outside of the acceptable range on both sides of the target value would be to multiply the approximate MID by 2. Therefore, the precision for this example is 6. \\[ MID*2 = precision \\] Choose a confidence level based on preference. In this case, we can choose a 95 percent confidence level. Since we have a n of 46 calculated from the solve_n function, the minimal sample size is 46. solve_n(precision = 6, sd =10, method = &quot;t-value&quot;) ## [1] 46 In conclusion, we can state the following: Assuming the standard deviation of 10, with 46 patients the mean PROMIS questionnaire scores can be estimated with a precision not exceeding a width of 6 points on a 95% confidence level (margin of error of 3 points). https://pubmed.ncbi.nlm.nih.gov/29200181/#&amp;gid=article-figures&amp;pid=figure-1-uid-0 1.7 Functions in R packages "],["one-sample-proportion-precision-based-sample-size.html", "2 One-sample proportion: precision-based sample size 2.1 Example 2.2 Data generating mechanism 2.3 Precision measures 2.4 Getting inputs, worst/best case scenarios 2.5 Simulation study 2.6 Example revisited 2.7 Functions in R packages", " 2 One-sample proportion: precision-based sample size 2.1 Example An educator wants to conduct a survey of first-year medical residents. The survey contains yes/no questions for several specific medical procedures asking whether they would be comfortable performing it without the presence of an attending physician. How many residents should he recruit? 2.2 Data generating mechanism Independent identically distributed variables \\(X_1, \\ldots, X_n \\sim Bernoulli(p)\\) with \\(p\\), the event probability as the parameter of interest. It will be estimated as the sample proportion \\(\\hat{p} = \\sum_{i=1}^n X_i / n\\). Inference can be based on the exact distribution of \\(X = \\sum_{i=1}^n X_i \\sim Binom(n,p)\\) or the asymptotic distribution of \\(\\hat{p} \\sim N(p, \\frac{p(1-p)}{n})\\). 2.3 Precision measures 2.3.1 Standard error The standard error of \\(\\hat{p}\\) is \\[\\begin{equation} SE(\\hat{p}) = \\sqrt\\frac{p(1-p)}{n}. \\end{equation}\\] Solving for \\(n\\), we have \\[\\begin{equation} n = \\frac{p(1-p)}{SE^2}, \\end{equation}\\] where \\(SE\\) is the targeted standard error of the estimate. #&#39; Calculate standard error for given sample size, or vice versa. Exactly one of &#39;n&#39; and &#39;se&#39; has to be NULL #&#39; p - expected event probability #&#39; n - sample size #&#39; se - standard error of estimated probability se_prop &lt;- function(p, n=NULL, se=NULL){ if (is.null(n) &amp; !is.null(se)){ n &lt;- p * (1-p) / se^2 } else if (!is.null(n) &amp; is.null(se)){ se &lt;- sqrt(p*(1-p)/n) } else stop(&quot;Exactly one of &#39;n&#39; and &#39;se&#39; has to be NULL&quot;) res &lt;- list(p = p, n = n, se = se) res } 2.3.2 Confidence interval Another way to quantify the precision of the estimated proportion is the width of the resulting two-sided confidence interval, usually at a 95% confidence level. The half of the width of a symmetric 95% confidence interval is also called the margin of error. There are several methods for estimating a confidence interval for a proportion, most of which resulting in non-symmetric intervals. Confidence interval methods Method \\(100(1-\\alpha)\\)% confidence interval Wald \\(\\Big(\\hat{p} \\pm z_*\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\Big)\\) Wilson \\(\\Big(\\hat{p}_{adj} \\pm \\frac{z_*}{1+z_*^2/n} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n} + \\frac{z_*^2}{4n^2}}\\Big)\\) Exact binomial \\((b_{1-\\frac{\\alpha}{2}; n,\\hat{p}}; b_{\\frac{\\alpha}{2}; n,\\hat{p}})\\) Agresti-Coull \\((\\hat{p}_{adj} \\pm z_*\\sqrt{p_{adj}(1-p_{adj})/n})\\) where \\(\\hat{p}_{adj} = \\frac{X + 0.5z_*^2}{n + z_*^2}\\), \\(b_{\\frac{\\alpha}{2}; n,p}\\) is the upper \\(\\frac{\\alpha}{2}\\)th quantile of the \\(Binomial(n,p)\\) distribution, \\(z_* = z_\\frac{\\alpha}{2}\\) denotes the upper \\(\\frac{\\alpha}{2}\\)th quantile of the standard normal distribution, and \\((a \\pm d)\\) is a shorthand for a symmetric confidence interval \\((a-d, a+d)\\) with margin of error \\(d\\). Base R implements the Wilson (prop.test when used with correct=FALSE) and the exact (binom.test) confidence intervals. The other intervals are available in packages, eg the binom package.1 The calculation of the sample size n or the confidence interval width is implemented in the presize R package.2,3 library(presize) str(prec_prop) ## function (p, n = NULL, conf.width = NULL, conf.level = 0.95, method = c(&quot;wilson&quot;, ## &quot;agresti-coull&quot;, &quot;exact&quot;, &quot;wald&quot;), ...) 2.4 Getting inputs, worst/best case scenarios The inputs needed to calculate the sample size are a best guess at \\(p\\), the proportion to be estimated the target precision defined as the standard error or confidence interval width The following plot shows how the sample size depends on these inputs: # set vector of &#39;p&#39; &amp; &#39;se&#39; values to explore p0 &lt;- seq(0.01, 0.99, by=0.01) s0 &lt;- c(0.1, 0.05, 0.025) # Data set with varying &#39;p&#39; and &#39;se&#39; se_settings &lt;- expand.grid(p = p0, se = s0) # Calculate &#39;n&#39; for each combination se_settings &lt;- transform(se_settings, n = se_prop(p=p, se=se)$n) library(ggplot2) ggplot(se_settings, aes(x = p, y = n, color = factor(se), group = se)) + geom_line() + scale_color_discrete(&quot;Standard error &#39;se&#39;&quot;) + xlab(&quot;Event probability &#39;p&#39;&quot;) + ylab(&quot;Sample size &#39;n&#39;&quot;) + ggtitle(&quot;Sample size required to achieve target standard error&quot;) # set vector of CI width values and CI methods to explore w0 &lt;- c(0.2, 0.1, 0.05) m0 &lt;- c(&quot;agresti-coull&quot;,&quot;wald&quot;, &quot;wilson&quot;,&quot;exact&quot;) # Data set with varying &#39;p&#39; and &#39;w&#39; ci_settings &lt;- expand.grid(p = p0, w = w0, Method=m0, stringsAsFactors = FALSE) # Calculate &#39;n&#39; for each combination # prec_prop is not vectorized for this calculation ci_settings$n &lt;- sapply(1:nrow(ci_settings), function(idx) with(ci_settings, prec_prop(p=p[idx], conf.width = w[idx], method = Method[idx])$n)) ggplot(ci_settings, aes(x = p, y = n, color = factor(w), linetype = Method, group = interaction(w, Method))) + geom_line() + scale_color_discrete(&quot;95% CI width &#39;w&#39;&quot;) + xlab(&quot;Event probability &#39;p&#39;&quot;) + ylab(&quot;Sample size &#39;n&#39;&quot;) + ggtitle(&quot;Sample size required to achieve target width of 95% CI&quot;) The following is evident from the plots (and the binomial variance formula): The largest sample size is needed for \\(p=0.5\\). If there is no a-prior information about the expected event probability, using the worst-case value of \\(p=0.5\\) in the calculations ensures that the target precision is reached (or exceeded) regardless of the true value. The required sample size decreases as we move away from \\(p=0.5\\) toward either end of the range. So if we can bound that expected event probability away from 0.5, ie \\(p &lt; p_L &lt; 0.5\\) or \\(p &gt; p_H &gt; 0.5\\), then we can use \\(p_L\\) or \\(p_H\\) in the calculations, and ensure that the target precision is reached (or exceeded) for any true value below \\(p_L\\) (or above \\(p_H\\)). The exact confidence interval method requires the largest sample size. The other methods give very similar results unless \\(p\\) is very close to 0 and 1. 2.5 Simulation study The simulation studies are set up to show how the actual confidence interval widths vary from the target values using the ‘n’ values computed above. library(binom) # create simulation settings with fewer values for &#39;p&#39; than in the plot sim_settings &lt;- rbind( expand.grid(p = seq(0.05, 0.95, by=0.05), precision = s0, method = &quot;SE&quot;, stringsAsFactors = FALSE), expand.grid(p = seq(0.05, 0.95, by=0.05), precision = w0, method = m0, stringsAsFactors = FALSE)) # function that, given &#39;p&#39;, method and planned sample size, simulates data &#39;R&#39; times and # computes the relevant confidence interval width # output is data frame with one row per simulation sim_se_ci &lt;- function(precision, p, method, R=1000){ if (method == &quot;SE&quot;){ n &lt;- se_prop(p=p, se=precision)$n } else { n &lt;- prec_prop(p=p, conf.width=precision, method = method)$n } # round up n &lt;- ceiling(n) # simulate data as binomial sum x &lt;- rbinom(R, size=n, prob=p) if (method == &quot;SE&quot;){ phat &lt;- x/n se &lt;- sqrt(phat * (1-phat) / n) res &lt;- data.frame(p = p, target = precision, method = &quot;SE&quot;, n=n, precision = se) } else { bmeth &lt;- if (method==&quot;wald&quot;) &quot;asymptotic&quot; else method df &lt;- binom.confint(x=x, n=n, methods=bmeth) res &lt;- data.frame(p = p, target = precision, method = method, n=n, precision = df$upper - df$lower) } res } # run simulation for each value of the grid set.seed(20576) sim_list &lt;- lapply(1:nrow(sim_settings), function(idx) with(sim_settings, sim_se_ci(precision = precision[idx], p = p[idx], method=method[idx]))) sim_res &lt;- do.call(rbind, sim_list) ggplot(sim_res, aes(x=p, y=precision, color = factor(target))) + facet_wrap(~method) + geom_hline(aes(yintercept = precision, color=factor(precision)), data=sim_settings) + geom_boxplot(aes(group=interaction(p, target)), outlier.size = 1, outlier.alpha = 0.2) + scale_color_discrete(&quot;Targeted precision&quot;) + xlab(&quot;Event probability &#39;p&#39;&quot;) + ylab(&quot;Simulated precision&quot;) 2.6 Example revisited 2.7 Functions in R packages References "],["one-sample-proportion-power-based-sample-size.html", "3 One-sample proportion: power-based sample size 3.1 Example 3.2 Data generating mechanism 3.3 Power-based sample size 3.4 Getting inputs, worst/best case scenarios 3.5 Example revisited 3.6 Simulation study 3.7 Functions in R packages", " 3 One-sample proportion: power-based sample size 3.1 Example An oncologist is developing a new treatment, and he wants to run a single arm phase II study to estimate the probability of response (partial or complete reduction in the size of the tumor) after four weeks of treatment. The current standard of care has a 30% response probability. How many subjects should he recruit? 3.2 Data generating mechanism Independent identically distributed variables \\(X_1, \\ldots, X_n \\sim Bernoulli(p)\\) with \\(p\\), the event probability as the parameter of interest. It will be estimated as the sample proportion \\(\\hat{p} = \\sum_{i=1}^n X_i / n\\). Inference can be based on the exact distribution of \\(X = \\sum_{i=1}^n X_i \\sim Binom(n,p)\\) or the asymptotic distribution of \\(\\hat{p} \\sim N(p, \\frac{p(1-p)}{n})\\). 3.3 Power-based sample size The sample size can also be based on the power to test, at a significance level \\(\\alpha\\), the null hypothesis \\(H_0: p = p_0\\) versus the two-sided alternative \\(H_{a1}: p \\neq p_0\\), or the one-sided alternatives \\(H_{a2}: p &gt; p_0\\) or \\(H_{a3}: p &lt; p_0\\). Test statistic There are three commonly used tests: Exact binomial test with test statistic \\(X = \\sum_{i=1}^n X_i \\sim Binom(n,p_0)\\) under \\(H_0\\) One-sample Wald z-test with test statistic \\(Z_W = \\frac{\\hat{p} - p_0}{\\sqrt{\\hat{p}(1-\\hat{p})/n}} \\approx N(0,1)\\) under \\(H_0\\) One-sample Score z-test with test statistic \\(Z_S = \\frac{\\hat{p} - p_0}{\\sqrt{p_0(1-p_0)/n}} \\approx N(0,1)\\) under \\(H_0\\) Rejection regions for the tests Test \\(H_{a1}: p \\neq p_0\\) \\(H_{a2}: p &gt; p_0\\) \\(H_{a3}: p &lt; p_0\\) Exact binomial \\(X \\geq b_{\\frac{\\alpha}{2}; n,p_0}\\) or \\(X \\leq b_{1-\\frac{\\alpha}{2}; n,p_0}\\) \\(X \\geq b_{\\alpha; n,p_0}\\) \\(X \\leq b_{1-\\alpha; n,p_0}\\) Wald z-test \\(|Z_W| \\geq z_\\frac{\\alpha}{2}\\) \\(Z_W \\geq z_\\alpha\\) \\(Z_W \\leq -z_{\\alpha}\\) Score z-test \\(|Z_S| \\geq z_\\frac{\\alpha}{2}\\) \\(Z_S \\geq z_\\alpha\\) \\(Z_S \\leq -z_{\\alpha}\\) where \\(b_{\\alpha; n,p_0}\\) is the upper \\(\\alpha\\)th quantile of the \\(Binomial(n,p_0)\\) distribution, and \\(z_{\\alpha}\\) is the upper \\(\\alpha\\)th quantile of the \\(N(0,1)\\) distribution. Power formula The power for a specific alternative \\(p=p_1\\) are shown for the one-sided alternative hypothesis \\(H_{a2}\\). The formula for \\(H_{a3}\\) is a straightforward modification, while the power for the two-sided hypothesis is the sum of the powers for the two one-sided hypotheses using \\(\\alpha/2\\) instead of \\(\\alpha\\). Power for the tests Test Prob(rejecting \\(H_0\\) versus \\(H_{a2}\\)) Exact binomial \\(1 - F_{B(n,p_1)}(b_{\\frac{\\alpha}{2}; n,p_0})\\) Wald z-test \\(1 - \\Phi\\Big(z_\\alpha - \\frac{p_1 - p_0}{\\sqrt{p_1(1-p_1)/n}}\\Big)\\) Score z-test \\(1 - \\Phi\\Big(z_\\alpha \\sqrt{\\frac{p_0(1-p_0)}{p_1(1-p_1)}} - \\frac{p_1 - p_0}{\\sqrt{p_1(1-p_1)/n}}\\Big)\\) where \\(F_{B(n,p)}\\) is the cdf of the \\(Binomial(n,p)\\) distribution, and \\(\\Phi\\) is the cdf of the \\(N(0,1)\\) distribution. #&#39; Calculate power for given sample size, or vice versa. Exactly one of &#39;n&#39; and &#39;power&#39; has to be NULL #&#39; p0 - null hypothesis event probability #&#39; p1 - alternative hypothesis event probability #&#39; n - sample size #&#39; power - power to reject the null hypothesis #&#39; sig.level - significance level of test #&#39; alternative - type of alternative hypothesis #&#39; test - type of test power.1prop.test &lt;- function(p, p0, n=NULL, power=NULL, sig.level=0.05, alternative=c(&quot;two.sided&quot;,&quot;less&quot;,&quot;greater&quot;), test = c(&quot;Wald&quot;,&quot;score&quot;,&quot;binomial&quot;)){ if (is.null(power) + is.null(n) != 1){ stop(&quot;Exactly one of &#39;n&#39; and &#39;power&#39; should be non-NULL&quot;) } alternative &lt;- match.arg(alternative) sides &lt;- ifelse(alternative==&quot;two.sided&quot;, 2, 1) test &lt;- match.arg(test) if (test == &quot;binomial&quot;){ p.body.up &lt;- quote({ ba &lt;- qbinom(sig.level/sides, size = n, prob=p0, lower.tail=FALSE) pbinom(ba, size=n, prob=p, lower.tail = FALSE)}) p.body.lo &lt;- quote({ ba &lt;- qbinom(sig.level/sides, size = n, prob=p0, lower.tail=TRUE) pbinom(ba-1, size=n, prob=p, lower.tail = TRUE)}) } else { za &lt;- qnorm(sig.level/sides, lower.tail = FALSE) vratio &lt;- if (test == &quot;score&quot;){ sqrt(p0 * (1-p0) / (p * (1-p)))} else 1 delta &lt;- (p0 - p)/sqrt(p*(1-p)) p.body.up &lt;- quote({ pnorm(za * vratio + delta * sqrt(n), lower.tail = FALSE) }) p.body.lo &lt;- quote({ pnorm(-za * vratio + delta * sqrt(n), lower.tail = TRUE) }) } p.body &lt;- if (alternative==&quot;two.sided&quot;) call(&quot;+&quot;, p.body.lo, p.body.up) else if (alternative==&quot;greater&quot;) p.body.up else p.body.lo if (is.null(power) &amp; !is.null(n)){ power &lt;- eval(p.body) } else if (!is.null(power) &amp; is.null(n)){ if (test == &quot;binomial&quot;){ n &lt;- 1 found &lt;- FALSE while (!found &amp; n &lt;= 1e+7){ n &lt;- n+1 pw &lt;- eval(p.body) found &lt;- (pw &gt;= power) } power &lt;- pw } else { f &lt;- function(n) {eval(p.body) - power} if (f(1) &gt; 0){ n &lt;- 1 } else { n &lt;- uniroot(f, c(1, 1e+07), tol = .Machine$double.eps^0.25, extendInt = &quot;upX&quot;)$root } } } METHOD &lt;- paste( switch(test, Wald = &quot;Wald z&quot;, score = &quot;Score z&quot;, binomial = &quot;Exact binomial&quot;), &quot;test power calculation&quot;) structure(list(n = n, p0 = p0, p = p, sig.level = sig.level, power = power, alternative = alternative, note = &quot;n is the number of independent samples&quot;, method = METHOD), class = &quot;power.htest&quot;) } 3.4 Getting inputs, worst/best case scenarios The inputs needed to calculate the sample size are a best guess at \\(p\\), the true value of the proportion to be tested the desired power of the study The following plot shows how the sample size depends on these inputs: # set vector of &#39;p0&#39;, &#39;p&#39; &amp; &#39;power&#39; values to explore p0 &lt;- c(0.2, 0.5, 0.8) p1 &lt;- seq(0.01, 0.99, by=0.01) pw0 &lt;- c(0.8, 0.95) m0 &lt;- c(&quot;Wald&quot;, &quot;score&quot;, &quot;binomial&quot;) # Data set with varying &#39;p&#39; and &#39;power&#39; pw_settings &lt;- expand.grid(p = p1, p0=p0, power = pw0, method = m0, stringsAsFactors = FALSE) # Calculate &#39;n&#39; for each combination pw_settings$n &lt;- sapply(1:nrow(pw_settings), function(idx) with(pw_settings, {if(p[idx] == p0[idx]) Inf else power.1prop.test(p=p[idx], p0=p0[idx], power=power[idx], test=method[idx])$n})) library(ggplot2) ggplot(pw_settings, aes(x = p, y = n, linetype = factor(power), color = method)) + facet_wrap(~p0) + geom_line() + geom_vline(aes(xintercept = p0)) + scale_color_discrete(&quot;Test&quot;) + scale_linetype_discrete(&quot;Target power&quot;) + xlab(&quot;Event probability &#39;p&#39;&quot;) + ylab(&quot;Sample size &#39;n&#39;&quot;) + ggtitle(&quot;Sample size required to achieve target standard error&quot;) + scale_y_log10() + theme(legend.position = &quot;top&quot;) 3.5 Example revisited 3.6 Simulation study 3.7 Functions in R packages "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
