[["one-sample-mean-precision-based-sample-size.html", "1 One-sample mean: precision-based sample size 1.1 Example 1.2 Data generating mechanism 1.3 Precision measures 1.4 Simulation study 1.5 Getting inputs 1.6 Example revisited 1.7 Functions in R packages", " 1 One-sample mean: precision-based sample size Co-author: Alyssa Bivens 1.1 Example The Patient-Reported Outcomes Measurement Information System (PROMIS) provides validated questionnaires for a wide range of quality-of-life outcomes in the domains of physical, mental, and social health. The responses from a subject are summarized with a T-score, which has a mean 50 and standard deviation of 10 in the US general population. An investigator wants to study anxiety in the population of patients with cyclic vomiting syndrome (CVS) using the PROMIS Anxiety scale to see if they report more anxiety (ie higher T-scores on the scale) than the general population. How many subjects are needed? 1.2 Data generating mechanism Independently identically distributed observations \\(X_1, \\ldots, X_n\\) with mean \\(\\mu\\) and standard deviation \\(\\sigma\\), with \\(\\mu\\) being the parameter of interest. The population mean \\(\\mu\\) is estimated by the sample mean \\(\\bar{X}_n\\) = \\(\\frac{\\sum(X_i)}{n}\\). 1.3 Precision measures 1.3.1 Standard error To calculate standard error (SE) or sample size (n) from standard error, it is \\(\\underline{not}\\) required for the underlying distribution to be normal. The standard error of sample mean is \\(SE(\\bar{X}) = \\frac{\\sigma}{\\sqrt{n}}\\). Solving for \\(n\\), we have \\[n= \\frac{\\sigma^{2}}{SE^2},\\] where SE is the targeted standard error of the estimate. #&#39;Calculate standard error for given sample size, or vice versa. Exactly one of &#39;n&#39; and &#39;se&#39; has to be NULL #&#39;sd - expected standard deviation #&#39;n - sample size #&#39;se - standard error of estimated mean se_mean &lt;- function (sd, n=NULL, se=NULL) { if(is.null(n) &amp; !is.null(se)) { (n&lt;-(sd^2)/se^2) } else if (!is.null(n) &amp; is.null(se)){ (se &lt;- sd/sqrt(n)) } else stop(&quot;Exactly one of &#39;n&#39; and &#39;se&#39; has to be NULL; &#39;sd&#39; must be known&quot;) res &lt;- list (n = n, sd = sd, se = se) res } 1.3.2 Confidence Interval Another way to quantify the precision of the estimated mean is the width of the resulting two-sided confidence interval, usually at a 95% confidence level. The half of the width of a symmetric 95% confidence interval is also called the margin of error. There are two methods for estimating a confidence interval for a mean, which result in symmetric intervals. We can use the \\(z\\)-based interval if the population standard deviation (\\(\\sigma\\)) is known, and the \\(t\\)-based confidence interval if \\(\\sigma\\) is unknown. The confidence intervals are computed under the assumption that the data are normally distributed. However, according to the central limit theorem, with a sufficiently large sample size \\(n\\), the sample mean \\(\\bar{X}_n\\) will be normally distributed regardless of the population distribution. The \\(100(1-\\alpha)\\)% confidence interval for \\(\\mu\\) when \\(\\sigma\\) is known is \\(CI = \\bar{X} \\pm z_{\\frac {\\alpha}{2}}\\frac{\\sigma}{ \\sqrt n}\\). The confidence interval when \\(\\sigma\\) is unknown is \\(CI = \\bar{X} \\pm t_{\\frac{\\alpha}{2}, n-1}\\frac{s}{\\sqrt n},\\) where \\(t_{\\frac {\\alpha}{2}, n-1}\\) is the upper \\(\\frac{\\alpha}{2}\\)th quantile of the \\(t\\)-distribution with \\(n-1\\) degrees of freedom, and \\(s\\) is the sample standard deviation. To understand the difference between the \\(z\\)-based interval and \\(t\\)-based interval, consider the following graph: sample_sizes &lt;- c(3, 4, 5, 10, 30, 50, 100, 200) df &lt;- c(sample_sizes - 1) t_values &lt;- qt(p=.05/2, df = df, lower.tail = FALSE) z &lt;- qnorm(p=.05/2, lower.tail=FALSE) xy &lt;- data.frame(n = sample_sizes, t = t_values, z = z) plot (xy$n, xy$t, type=&#39;o&#39;, col = &#39;red&#39;, xlab = &quot;Sample Size&quot;, ylab = &quot;Critical-Values&quot;, main = &quot;Critical-Values by Sample Size at 95% Confidence Level&quot;) points(xy$n, xy$z, col=&#39;blue&#39;, type=&quot;o&quot;, pch=4) legend(&quot;topright&quot;, legend = c(&quot;t-values&quot;, &quot;z-values&quot;), col=c(&quot;red&quot;, &quot;blue&quot;), pch=c(1,4), lty=1) The red line represents the \\(t\\) critical values associated with various sample sizes; the blue line represents the constant value of 1.959964, which is the \\(z\\) critical value. We can see that as the the sample size increases, the \\(t\\) critical value approaches the \\(z\\) critical value. The difference becomes small by a sample size of 30, which is the typically quoted cutoff for using the asymptotic test. The difference is barely noticeable after a sample size of 100. Overall, this shows that, in many instances, the difference between using a \\(t\\) critical-value and using a \\(z\\) critical-value is negligible. The prec_mean function in {presize} provides the sample size calculation for the \\(t\\)-based confidence interval. library(presize) str(prec_mean) ## function (mean, sd, n = NULL, conf.width = NULL, conf.level = 0.95, ..., ## mu = NULL) Note that the formulas above imply that the mean is a superfluous parameter, and can be set to any value. For completeness, the following function implements a \\(z\\)-based computation. # Function that can find the n or conf.width based on what is null. prec_mean_z &lt;- function (sd, n = NULL, conf.width = NULL, conf.level=.95) { alpha &lt;- (1-conf.level)/2 z &lt;- qnorm(alpha, lower.tail = FALSE) if(is.null(conf.width) &amp; !is.null(n)) { ci&lt;- (z*(sd/sqrt(n))) conf.width &lt;- 2 * ci res &lt;- list (sd = sd, n = n, conf.width = conf.width, conf.level = conf.level) res } else if(!is.null(conf.width) &amp; is.null(n)) { ci &lt;- conf.width/2 n &lt;- ((sd*z)/ci)^2 } else stop (&quot;Exactly one of &#39;n&#39; and &#39;conf.width&#39; must be NULL&quot;) res &lt;- list (sd = sd, n = n, conf.width = conf.width, conf.level = conf.level) res } 1.4 Simulation study # Write function to get n solve_n &lt;- function (precision, sd, conf.level=.95, n = NULL, method = c(&quot;SE&quot;, &quot;t-value&quot;, &quot;z-value&quot;)) { method &lt;- match.arg(method, choices = c(&quot;SE&quot;, &quot;t-value&quot;, &quot;z-value&quot;)) if (method == &quot;SE&quot;) { n &lt;- se_mean(sd = sd, n = NULL, se = precision)$n } else if(method == &quot;z-value&quot;) { n &lt;- prec_mean_z(sd = sd, n = NULL, conf.width = precision, conf.level = conf.level)$n } else if(method == &quot;t-value&quot;) { n &lt;- prec_mean (mean = 0, conf.width = precision, conf.level = conf.level, sd = sd)$n } else stop (&quot;&#39;method&#39; must be &#39;z&#39;, &#39;t&#39;, or &#39;SE&#39;&quot;) n &lt;- ceiling(n) return(n) } #Find n based on various sd, method, or, p. ## set vector of precision values (p0) and methods (m0) to explore p0 &lt;- seq(1, 5, by=.5) sd0 &lt;- 10 m0 &lt;- c(&quot;SE&quot;, &quot;t-value&quot;, &quot;z-value&quot;) # Data set with varying &#39;mean&#39; and &#39;w&#39; se_settings &lt;- expand.grid(p = p0, sd = sd0, m = m0, stringsAsFactors = FALSE) # Apply the sim mean functions to all possibilities like se_settings se_settings$n &lt;- sapply(1:nrow(se_settings), function(idx) with (se_settings, solve_n (precision = p[idx], sd = sd[idx], method = m[idx]))) library(ggplot2) ggplot(se_settings, aes(x = p, y = n, color = m, group = m)) + geom_line()+ scale_color_discrete(&quot;Method&quot;) + xlab(&quot;Target precision &#39;p&#39;&quot;) + ylab(&quot;Sample size &#39;n&#39;&quot;) + ggtitle(&quot;Sample size required to achieve target precision&quot;) Graph various simulated precision’s for various methods, distributions, and target precisions. # set up possible values for target precision, standard deviation, method, and distribution. p0 &lt;- seq(1, 5, by=.5) sd0 &lt;- 10 m0 &lt;- c(&quot;SE&quot;, &quot;t-value&quot;, &quot;z-value&quot;) d0 &lt;- c(&quot;normal&quot;, &quot;uniform&quot;, &quot;exp&quot;) sim_settings &lt;- rbind( expand.grid( sd = sd0, p = p0, method = m0, stringsAsFactors = FALSE, distribution = d0), expand.grid( sd = sd0, p = p0, method = m0, stringsAsFactors = FALSE, distribution = d0 )) # Allow function to be used from presize library(presize) # Create a function to calculate the simulated precisions. sim_mean &lt;- function (sd, n=NULL, conf.level = .95, precision, R = 1000, method = c(&quot;SE&quot;, &quot;t-value&quot;, &quot;z-value&quot;), distribution = c(&quot;normal&quot;, &quot;uniform&quot;, &quot;exp&quot;)) { # Allow variants of SE, t-value, and z-value; prevent non-characters from being allowed. method &lt;- match.arg(method, choices = c(&quot;SE&quot;, &quot;t-value&quot;, &quot;z-value&quot;)) # Find sample size (n) depending on method. if (method == &quot;SE&quot;) { n&lt;-(sd^2)/precision^2 } else if(method == &quot;z-value&quot;) { alpha &lt;- (1-conf.level)/2 z &lt;- qnorm(alpha, lower.tail = FALSE) ci &lt;- precision/2 n &lt;- ((sd*z)/ci)^2 } else if(method == &quot;t-value&quot;) { n &lt;- prec_mean (mean = 0, conf.width = precision, conf.level = conf.level, sd = sd)$n } else stop (&quot;&#39;method&#39; must be &#39;z&#39;, &#39;t&#39;, or &#39;SE&#39;&quot;) # Round n up to nearest interger. n &lt;- ceiling(n) #Simulate possible outcome with the predicted SD and the predicted n and various distributions. if (distribution == &quot;normal&quot;) se_vec &lt;- replicate (R, {x &lt;- rnorm(n = n, mean = 0, sd = sd); sd_x = sd(x); sd_x/sqrt(n)}) if (distribution == &quot;uniform&quot;) se_vec &lt;- replicate (R, {x &lt;- runif(n = n, min = 0, max = sd*sqrt(12)); sd_x = sd(x); sd_x/sqrt(n)}) ## To use the runif function the min and max must be calculated in relationship to standard deviation*. if (distribution == &quot;exp&quot;) se_vec &lt;- replicate (R, {x &lt;- rexp(n = n, rate = 1/sd); sd_x = sd(x); sd_x/sqrt(n)}) ##To use the rexp function the rate must be calculated in relationship to standard deviation**. if (method == &quot;t-value&quot;) { t_value &lt;- qt(p= (1 - conf.level)/2, df = n - 1, lower.tail = FALSE) t_ci &lt;- 2*(t_value*se_vec) } if (method == &quot;z-value&quot;) { z_value &lt;- qnorm (p = (1 - conf.level)/2, lower.tail = FALSE) z_ci &lt;- 2*(z_value*se_vec) } if (method == &quot;SE&quot;) { precision_dataframe &lt;- data.frame(sd = sd, n = n, method = &quot;SE&quot;, distribution = distribution, precision = se_vec, target = precision) } if (method == &quot;t-value&quot;) { precision_dataframe &lt;- data.frame(sd = sd, n = n, method = &quot;t-value&quot;, distribution = distribution, precision = t_ci, target = precision) } if (method == &quot;z-value&quot;) { precision_dataframe &lt;- data.frame(sd = sd, n = n, method = &quot;z-value&quot;, distribution = distribution, precision = z_ci, target = precision) } return(precision_dataframe) } #Run simulation for each value of the grid: set.seed(12345) sim_list &lt;- lapply (1:nrow(sim_settings), function(idx) with (sim_settings, sim_mean(precision = p[idx], sd = sd0, method = method[idx], distribution = distribution[idx], R = 1000))) sim_res &lt;- do.call(rbind, sim_list) # Graph sim_res library(ggplot2) ggplot(sim_res, aes (x=target, y = precision, color = factor(method))) + facet_grid(method~distribution, scales = &quot;free_y&quot;) + geom_boxplot(aes(group=interaction(method, distribution, target)), outlier.size = 1, outlier.alpha = 0.025) + scale_color_discrete(&quot;Targeted precision&quot;) + geom_abline(intercept = 0, slope = 1) Notes In the uniform distribution \\(\\frac{1}{\\sqrt{12}}(b-a) = sd\\) where b is the maximum, a is the minimum, and sd is the standard deviation. Because we only need to know the range, we can assign a value to a and solve it in relationship to b. Therefore, we can assign a (the minimum) as 0 and solve for b (the maximum). After solving for the maximum (b), we calculate that \\(b = sd*\\sqrt{12}\\). In the exponent distribution \\(sd = \\frac{1}{\\lambda}\\), where \\(\\lambda = rate\\). Therefore solving for rate, we calculate that \\(\\lambda = \\frac{1}{sd}\\). 1.5 Getting inputs 1.5.1 Estimating Standard Deviation To estimate n from sample error (or vice versa), standard deviation must be either known or estimated. Some ways to obtain an already known standard deviation, include researching standard deviations obtained from similar studies or using a universal, known standard deviation (depending on the type of study). If standard deviation cannot be obtained in this way, it must be estimated. Use information known about the value being collected to estimate an approximate minimum value collected and an approximate maximum value. For example, height of adults can have an estimated minimum collected value of 4 ft and 9 inches and estimated maximum collected value of 6 feet and 2 inches. While there are adults with heights below 4 feet and 9 inches and above 6 feet and 3 inches, they are very uncommon and therefore (by probability) not likely to be in the sample. Ideally, this will give a range close to the range of the data collected. After a range is estimated, we can then us a formula called the range rule for standard deviation which states the following: sd \\(\\approx \\frac{max-min}{4}\\) where sd = standard deviation, max = estimated maximum value, and min = estimated minimum value. #&#39; Calculate sample standard deviation for a given range. There must be exactly one one &#39;max&#39; and one &#39;min.&#39; #&#39; sd = standard deviation #&#39; max = estimated maximum value #&#39; min = estimated minimum value sd_from_range &lt;- function (max=max, min=min, sd=NULL) { sd &lt;- (max - min)/4 return(sd) } 1.6 Example revisited As stated in the example, we want to calculate the sample size (n) based on a t-score method and a claimed standard deviation of 10. Additionally, we know the mean is 50, but this is an unnecessary fact for calculating n. Since we are only finding the sample size, we would use the solve_n function created earlier. In order to find n, we need standard deviation, precision, and a chosen confidence level. The example gives us a known standard deviation of 10. To estimate precision, we can use other studies with similar studies and use what was obtained in them or use studies that determine minimally important differences (MIDs). For example, in this study we can use a study from the National Library of Medicine titled “estimating minimally important differences for the PROMIS pain interference scales: results from 3 randomized clinic trials” to determine an approximate minimally important differences (Source 1). Using the data, we can estimate a minimum importance difference (MID) of around 3 (Source 1), which means that in order to get the confidence width (or precision), which calculates the likelihood of it being outside of the acceptable range on both sides of the target value would be to multiply the approximate MID by 2. Therefore, the precision for this example is 6. \\[ MID*2 = precision \\] Choose a confidence level based on preference. In this case, we can choose a 95 percent confidence level. Since we have a n of 46 calculated from the solve_n function, the minimal sample size is 46. solve_n(precision = 6, sd =10, method = &quot;t-value&quot;) ## [1] 46 In conclusion, we can state the following: Assuming the standard deviation of 10, with 46 patients the mean PROMIS questionnaire scores can be estimated with a precision not exceeding a width of 6 points on a 95% confidence level (margin of error of 3 points). https://pubmed.ncbi.nlm.nih.gov/29200181/#&amp;gid=article-figures&amp;pid=figure-1-uid-0 1.7 Functions in R packages "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
